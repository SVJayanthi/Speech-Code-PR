{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a007ee42-4212-4b9b-bb5e-bbad45130e03",
   "metadata": {},
   "source": [
    "# End to End Demo of Speech-2-PR AI\n",
    "\n",
    "Install packages in `requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d5062-c6d2-4e0d-bac9-b2a36fd52cfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308d88ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srava\\Anaconda3\\envs\\speech2code\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib.util\n",
    "import ast\n",
    "import re\n",
    "import librosa\n",
    "import torch\n",
    "import qdrant_client\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfa5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "from github.GithubException import GithubException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e0ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"openaikey\"] = input(\"Please enter your Open AI API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da4e71c1-073a-41d1-8be7-5aa5458db08d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T17:09:23.238907Z",
     "iopub.status.busy": "2024-06-21T17:09:23.238586Z",
     "iopub.status.idle": "2024-06-21T17:09:23.263944Z",
     "shell.execute_reply": "2024-06-21T17:09:23.263113Z",
     "shell.execute_reply.started": "2024-06-21T17:09:23.238886Z"
    }
   },
   "outputs": [],
   "source": [
    "class OpenAILLM:\n",
    "    def __init__(self, model_name=\"gpt-4o\", max_tokens=1000):\n",
    "        self.openai_client = OpenAI(\n",
    "            api_key=os.getenv(\"openaikey\"))\n",
    "        assert(model_name in [model.id for model in self.openai_client.models.list().data])\n",
    "        self.model_name = model_name\n",
    "        self.max_tokens = max_tokens\n",
    "    \n",
    "    def call_llm(self, prompt):\n",
    "        text_list = [{\"type\": \"text\", \"text\": prompt}]\n",
    "        try:\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": text_list,\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=self.max_tokens,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return \"LLM Failed, please try again\"\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def __call__(self, prompt):\n",
    "        return  self.call_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e01c41e-f9ac-485c-8f5a-eeca4a777092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T17:09:23.834761Z",
     "iopub.status.busy": "2024-06-21T17:09:23.834436Z",
     "iopub.status.idle": "2024-06-21T17:09:23.839946Z",
     "shell.execute_reply": "2024-06-21T17:09:23.839296Z",
     "shell.execute_reply.started": "2024-06-21T17:09:23.834738Z"
    }
   },
   "outputs": [],
   "source": [
    "def getLlm(max_tokens=1000):\n",
    "    return OpenAILLM(max_tokens=max_tokens)\n",
    "\n",
    "def runLlm(llm, formattedPrompt):\n",
    "   return llm(formattedPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75272d6b-8bb0-49c8-b844-4b288a052684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T17:09:24.824397Z",
     "iopub.status.busy": "2024-06-21T17:09:24.824046Z",
     "iopub.status.idle": "2024-06-21T17:09:25.469906Z",
     "shell.execute_reply": "2024-06-21T17:09:25.469198Z",
     "shell.execute_reply.started": "2024-06-21T17:09:24.824378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = getLlm()\n",
    "runLlm(llm,\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695e092-5f79-45ba-aa72-6ed3003e5493",
   "metadata": {},
   "source": [
    "## Part A: Upload your audio file (meeting audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc198ec8-bf40-43a3-b7bc-6f8b06543fae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:24:19.877943Z",
     "iopub.status.busy": "2024-06-21T18:24:19.877638Z",
     "iopub.status.idle": "2024-06-21T18:24:19.882705Z",
     "shell.execute_reply": "2024-06-21T18:24:19.881425Z",
     "shell.execute_reply.started": "2024-06-21T18:24:19.877921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your audio file using librosa\n",
    "def load_audio(file_path, target_sample_rate=16000):\n",
    "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "    if sample_rate != target_sample_rate:\n",
    "        audio = librosa.resample(audio, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
    "    return audio, target_sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cc42a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your audio file (replace 'your_audio_file.wav' with the path to your audio file)\n",
    "audio_file_path = 'DesignDiscussion.wav'\n",
    "audio, sample_rate = load_audio(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212053d-3177-48af-8811-376d61989158",
   "metadata": {},
   "source": [
    "## Part B: Use ASR (Whisper) to transcribe meeting audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0acfd59a-9d59-4c12-b89c-5aaecbc22d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:24:27.823740Z",
     "iopub.status.busy": "2024-06-21T18:24:27.823331Z",
     "iopub.status.idle": "2024-06-21T18:24:29.154235Z",
     "shell.execute_reply": "2024-06-21T18:24:29.153579Z",
     "shell.execute_reply.started": "2024-06-21T18:24:27.823707Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srava\\Anaconda3\\envs\\speech2code\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model and processor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-small\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70f4b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    }
   ],
   "source": [
    "# Convert waveform to numpy array and create a sample dictionary\n",
    "sample = {\n",
    "    \"array\": audio,\n",
    "    \"sampling_rate\": sample_rate\n",
    "}\n",
    "\n",
    "result = pipe(sample)\n",
    "transcript_text = result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40c7645-5dbd-49da-8c65-5e8ca66b3395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:24:49.030554Z",
     "iopub.status.busy": "2024-06-21T18:24:49.030327Z",
     "iopub.status.idle": "2024-06-21T18:24:49.034196Z",
     "shell.execute_reply": "2024-06-21T18:24:49.033616Z",
     "shell.execute_reply.started": "2024-06-21T18:24:49.030535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi all, thanks for joining. Today we're going to discuss the feature revamp for the multimodal RAG application to improve user experience. First on our list is adding a chat functionality to the application so that users can maintain chat history and ask questions over some of the previous interactions they've had with the application. In order to work successfully we need to ensure there is a chat reset, a chat delete, and a chat modal that keeps track of all the different chats our user is having with their application in context.\n"
     ]
    }
   ],
   "source": [
    "print(transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d60f73-656c-4139-a8b0-c53be3592a4a",
   "metadata": {},
   "source": [
    "## Part C: Build a Code Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42c09a69-b22f-4393-b9e2-9ec2c5876d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:25:54.823649Z",
     "iopub.status.busy": "2024-06-21T18:25:54.823278Z",
     "iopub.status.idle": "2024-06-21T18:25:54.828188Z",
     "shell.execute_reply": "2024-06-21T18:25:54.827489Z",
     "shell.execute_reply.started": "2024-06-21T18:25:54.823622Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "### Instructions for Extracting Information for a Code Spec\n",
    "\n",
    "1. **Objective Statement:**\n",
    "   - Identify and extract statements that describe the overall goal or purpose of the feature being discussed. Look for phrases like \"the purpose of this feature is...\" or \"the main objective is...\".\n",
    "\n",
    "2. **Requirements:**\n",
    "   - **Functional Requirements:**\n",
    "     - Extract details that describe what the system should do. Look for specific functionalities, behaviors, or actions that the feature must perform. Key phrases might include \"the system must...\", \"the feature should allow...\", \"it needs to...\", etc.\n",
    "   - **Non-functional Requirements:**\n",
    "     - Identify requirements that describe how the system performs certain functions. These might include performance metrics, usability standards, reliability, and other quality attributes. Look for phrases like \"it should be fast...\", \"it must be secure...\", \"it needs to handle up to X users...\", etc.\n",
    "\n",
    "3. **Use Case/User Story:**\n",
    "   - Extract information that details how a user will interact with the feature. Look for narratives or scenarios that describe the user’s actions and interactions with the system. Phrases might include \"as a user, I want to...\", \"the user will...\", \"in this scenario...\".\n",
    "\n",
    "4. **Deliverables:**\n",
    "   - **Design New File:**\n",
    "     - Identify references to creating new files or components as part of the feature implementation. Look for phrases like \"we need to create a new...\", \"design a new...\", etc.\n",
    "   - **Modify Existing File:**\n",
    "     - Extract details about changes to existing files or components. Look for phrases like \"we will modify...\", \"update the existing...\", etc.\n",
    "   - **Documentation:**\n",
    "     - Identify information about required documentation. Look for mentions of writing, documenting, or adding comments in the repository. Phrases might include \"document the...\", \"write the docs...\", \"add comments to...\".\n",
    "\n",
    "---\n",
    "\n",
    "### Example Analysis\n",
    "\n",
    "**Objective Statement:**\n",
    "- Extract: \"The main objective of this feature is to provide users with a seamless experience when accessing their profile.\"\n",
    "\n",
    "**Requirements:**\n",
    "- **Functional:**\n",
    "  - Extract: \"The system must allow users to update their profile information.\"\n",
    "  - Extract: \"The feature should enable users to upload profile pictures.\"\n",
    "- **Non-functional:**\n",
    "  - Extract: \"The profile update process should be completed within 2 seconds.\"\n",
    "  - Extract: \"The system must be able to handle 10,000 concurrent profile updates.\"\n",
    "\n",
    "**Use Case/User Story:**\n",
    "- Extract: \"As a user, I want to be able to change my profile picture so that I can personalize my account.\"\n",
    "\n",
    "**Deliverables:**\n",
    "- **Design New File:**\n",
    "  - Extract: \"We need to design a new profile picture upload module.\"\n",
    "- **Modify Existing File:**\n",
    "  - Extract: \"We will update the user model to include the new profile picture attribute.\"\n",
    "- **Documentation:**\n",
    "  - Extract: \"Document the new API endpoints for profile updates in the repository.\"\n",
    "\n",
    "---\n",
    "Use the structure above to generate a code spec from the following meeting transcript. The output will be a summary that does not have to include timestamp nor keep the original sentence structure. Keep the number of bullet points minimal while keeping essential information.\n",
    "\n",
    "---\n",
    "{transcript_text}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94c26b65-fa9c-4bd5-9ede-bda13429c05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:25:54.829603Z",
     "iopub.status.busy": "2024-06-21T18:25:54.829392Z",
     "iopub.status.idle": "2024-06-21T18:26:09.242604Z",
     "shell.execute_reply": "2024-06-21T18:26:09.241897Z",
     "shell.execute_reply.started": "2024-06-21T18:25:54.829587Z"
    }
   },
   "outputs": [],
   "source": [
    "code_spec = runLlm(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da9180d-10d4-4872-bc59-5102f3ef96a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:26:09.243833Z",
     "iopub.status.busy": "2024-06-21T18:26:09.243628Z",
     "iopub.status.idle": "2024-06-21T18:26:09.247125Z",
     "shell.execute_reply": "2024-06-21T18:26:09.246597Z",
     "shell.execute_reply.started": "2024-06-21T18:26:09.243816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Code Spec for Multimodal RAG Application Feature Revamp\n",
      "\n",
      "**Objective Statement:**\n",
      "- The main objective of this feature is to provide an enhanced user experience by adding chat functionality to the multimodal RAG application.\n",
      "\n",
      "**Requirements:**\n",
      "- **Functional:**\n",
      "  - The system must allow users to maintain chat history.\n",
      "  - The feature should enable users to ask questions based on their previous interactions.\n",
      "  - The system must include functionalities for chat reset and chat delete.\n",
      "- **Non-functional:**\n",
      "  - N/A (not specified in the transcript).\n",
      "\n",
      "**Use Case/User Story:**\n",
      "- As a user, I want to maintain and interact with chat history to ask follow-up questions based on my previous interactions with the application.\n",
      "\n",
      "**Deliverables:**\n",
      "- **Design New File:**\n",
      "  - Design a new chat modal to keep track of all the different chats in context.\n",
      "- **Modify Existing File:**\n",
      "  - N/A (not specified in the transcript).\n",
      "- **Documentation:**\n",
      "  - Document the new chat functionalities including chat reset and delete in detail.\n"
     ]
    }
   ],
   "source": [
    "print(code_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60834bd-7c82-48f9-80f0-34875d5f7541",
   "metadata": {},
   "source": [
    "## Part D: Retrieve relevant files from RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ba717",
   "metadata": {},
   "source": [
    "### Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99a3913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Multimodal-RAG'...\n"
     ]
    }
   ],
   "source": [
    "!git clone \"git@github.com:SVJayanthi/Multimodal-RAG.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337e417-164f-4057-971e-f9f61cef2ca9",
   "metadata": {},
   "source": [
    "### Setup Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db8941fa-58b0-4772-8458-d07f5e4d1a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:26:52.823145Z",
     "iopub.status.busy": "2024-06-21T18:26:52.822857Z",
     "iopub.status.idle": "2024-06-21T18:26:52.837375Z",
     "shell.execute_reply": "2024-06-21T18:26:52.836729Z",
     "shell.execute_reply.started": "2024-06-21T18:26:52.823127Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each file in a directory, get source code & metadata about file_name / dir\n",
    "## Ingest .py files\n",
    "\n",
    "def get_file_metadata_and_content(directory):\n",
    "    supported_extensions = ('.py')\n",
    "    files_data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(supported_extensions):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                file_data = {\n",
    "                    'file_name': file,\n",
    "                    'file_path': file_path,\n",
    "                    'content': content\n",
    "                }\n",
    "                files_data.append(file_data)\n",
    "    \n",
    "    return files_data\n",
    "\n",
    "# Example usage\n",
    "directory_path = 'Multimodal-RAG'\n",
    "files_metadata_and_content = get_file_metadata_and_content(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "931c1c51-f104-4e3b-bf0d-5801d9c09df2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:26:53.823066Z",
     "iopub.status.busy": "2024-06-21T18:26:53.822779Z",
     "iopub.status.idle": "2024-06-21T18:26:53.827448Z",
     "shell.execute_reply": "2024-06-21T18:26:53.826851Z",
     "shell.execute_reply.started": "2024-06-21T18:26:53.823048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_metadata_and_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96fc0f1e-b8f9-4376-b946-96293772f061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:00.823555Z",
     "iopub.status.busy": "2024-06-21T18:27:00.823235Z",
     "iopub.status.idle": "2024-06-21T18:27:00.827792Z",
     "shell.execute_reply": "2024-06-21T18:27:00.827279Z",
     "shell.execute_reply.started": "2024-06-21T18:27:00.823531Z"
    }
   },
   "outputs": [],
   "source": [
    "collection_name = \"code_collection\"\n",
    "def setup_retriever(corpus_data, embed_ids=True):\n",
    "    q_client = qdrant_client.QdrantClient(\":memory:\")\n",
    "    if embed_ids:\n",
    "        corpus_texts = [\"File Name: \"+i['file_name'] + \"\\n \" + i['content'] for i in corpus_data]\n",
    "    else:\n",
    "        corpus_texts = [i['text'] for i in corpus_data]\n",
    "    \n",
    "    q_client.add(\n",
    "        collection_name,\n",
    "        documents = corpus_texts,\n",
    "        metadata=corpus_data,\n",
    "    )\n",
    "\n",
    "    return q_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ce226f3-9f9e-4bf5-9e42-2e75d9aa27b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:00.950520Z",
     "iopub.status.busy": "2024-06-21T18:27:00.950197Z",
     "iopub.status.idle": "2024-06-21T18:27:23.560263Z",
     "shell.execute_reply": "2024-06-21T18:27:23.559606Z",
     "shell.execute_reply.started": "2024-06-21T18:27:00.950498Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77.7M/77.7M [00:01<00:00, 63.9MiB/s]\n"
     ]
    }
   ],
   "source": [
    "retriever = setup_retriever(files_metadata_and_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105338df-cd4f-4bd3-9ca3-ef184db11e5c",
   "metadata": {},
   "source": [
    "### Code Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2430a227-28a1-42bd-8513-6eb9201c0fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:23.561521Z",
     "iopub.status.busy": "2024-06-21T18:27:23.561336Z",
     "iopub.status.idle": "2024-06-21T18:27:23.565670Z",
     "shell.execute_reply": "2024-06-21T18:27:23.565051Z",
     "shell.execute_reply.started": "2024-06-21T18:27:23.561504Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve(retriever, question, top_k=3):\n",
    "    search_result = retriever.query(\n",
    "        collection_name=collection_name,\n",
    "        query_text=question,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bf48640-b61c-4554-a423-c16b3ea41d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:23.566502Z",
     "iopub.status.busy": "2024-06-21T18:27:23.566338Z",
     "iopub.status.idle": "2024-06-21T18:27:23.851370Z",
     "shell.execute_reply": "2024-06-21T18:27:23.850445Z",
     "shell.execute_reply.started": "2024-06-21T18:27:23.566487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multimodal-RAG\\\\chatapp\\\\chatapp\\\\chatapp.py'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = retrieve(retriever, transcript_text, 10)\n",
    "file_paths = [r.metadata['file_path'] for r in results]\n",
    "selected_file_path = file_paths[0]\n",
    "selected_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f137e-98f3-407f-8ac2-5d9a94b3cd21",
   "metadata": {},
   "source": [
    "## Part E: Build Context for File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81317fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imports(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        tree = ast.parse(file.read(), filename=file_path)\n",
    "    imports = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for alias in node.names:\n",
    "                imports.append(alias.name)\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            if node.module:\n",
    "                imports.append(node.module)\n",
    "    return imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9aba79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_local_module(module_name, repo_path):\n",
    "    module_path = os.path.join(repo_path, *module_name.split('.'))\n",
    "    return (os.path.isfile(f\"{module_path}.py\") or os.path.isdir(module_path))\n",
    "\n",
    "def get_local_imports(imports, repo_path):\n",
    "    local_imports = []\n",
    "    for imp in imports:\n",
    "        if is_local_module(imp, repo_path):\n",
    "            local_imports.append(imp)\n",
    "    return local_imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "181f098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal-RAG\\chatapp\\reflex\n",
      "Multimodal-RAG\\chatapp\\chatapp\\components\n",
      "Multimodal-RAG\\chatapp\\chatapp\\state\n",
      "Multimodal-RAG\\chatapp\\chatapp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['chatapp.components', 'chatapp.state', 'chatapp']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_local_imports(extract_imports(selected_file_path),  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef4ff9ee-d4e2-4c21-b38b-0b85be66d316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:40.823170Z",
     "iopub.status.busy": "2024-06-21T18:27:40.822867Z",
     "iopub.status.idle": "2024-06-21T18:27:40.828091Z",
     "shell.execute_reply": "2024-06-21T18:27:40.827191Z",
     "shell.execute_reply.started": "2024-06-21T18:27:40.823136Z"
    }
   },
   "outputs": [],
   "source": [
    "def gather_code_and_imports(file_path, repo_path, gathered_files=None):\n",
    "    if gathered_files is None:\n",
    "        gathered_files = set()\n",
    "\n",
    "    if file_path in gathered_files:\n",
    "        return \"\"\n",
    "    \n",
    "    gathered_files.add(file_path)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        code = file.read()\n",
    "\n",
    "    imports = extract_imports(file_path)\n",
    "    local_imports = get_local_imports(imports, repo_path)\n",
    "\n",
    "    for local_module in local_imports:\n",
    "        local_file_path = os.path.join(repo_path, *local_module.split('.')) + \".py\"\n",
    "        if os.path.isfile(local_file_path):\n",
    "            code += gather_code_and_imports(local_file_path, repo_path, gathered_files)\n",
    "    \n",
    "    return code\n",
    "\n",
    "def get_all_code(main_file_path, repo_path):\n",
    "    return gather_code_and_imports(main_file_path, repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd964ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"Multimodal-RAG\\chatapp\"\n",
    "combined_context = get_all_code(selected_file_path, repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48e6cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathers code and imports from a given file, annotating with filenames and tracking hierarchy\n",
    "def gather_code_and_imports(file_path, repo_path, gathered_files=None, file_hierarchy=None):\n",
    "    if gathered_files is None:\n",
    "        gathered_files = set()\n",
    "    if file_hierarchy is None:\n",
    "        file_hierarchy = {}\n",
    "\n",
    "    if file_path in gathered_files:\n",
    "        return \"\", file_hierarchy\n",
    "    \n",
    "    gathered_files.add(file_path)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        code = file.read()\n",
    "    \n",
    "    annotated_code = f\"# Begin of {file_path}\\n{code}\\n# End of {file_path}\\n\"\n",
    "    \n",
    "    imports = extract_imports(file_path)\n",
    "    local_imports = get_local_imports(imports, repo_path)\n",
    "\n",
    "    file_hierarchy[file_path] = []\n",
    "\n",
    "    for local_module in local_imports:\n",
    "        local_file_path = os.path.join(repo_path, *local_module.split('.')) + \".py\"\n",
    "        if os.path.isfile(local_file_path):\n",
    "            file_hierarchy[file_path].append(local_file_path)\n",
    "            sub_code, file_hierarchy = gather_code_and_imports(local_file_path, repo_path, gathered_files, file_hierarchy)\n",
    "            annotated_code += sub_code\n",
    "    \n",
    "    return annotated_code, file_hierarchy\n",
    "\n",
    "# Gets all code from the main file and its local imports, and provides the file hierarchy\n",
    "def get_all_code(main_file_path, repo_path):\n",
    "    code, file_hierarchy = gather_code_and_imports(main_file_path, repo_path)\n",
    "    return code, file_hierarchy\n",
    "\n",
    "# Displays the file hierarchy in a readable format\n",
    "def display_file_hierarchy(file_hierarchy, indent=0):\n",
    "    f_string = \"\"\n",
    "    for file, imports in file_hierarchy.items():\n",
    "        f_string += (' ' * indent + os.path.basename(file)) + \"\\n\"\n",
    "        if imports:\n",
    "            f_string += \"imports from \" + display_file_hierarchy({imp: file_hierarchy[imp] for imp in imports}, indent + 4)\n",
    "    return f_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a221ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"Multimodal-RAG\\chatapp\"\n",
    "combined_context, file_hierarchy = get_all_code(selected_file_path, repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bae067-b35a-4cc5-812b-b1f764afb965",
   "metadata": {},
   "source": [
    "## Part F: Perform Code Change(s) using Code Spec & Context about File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8644264a-888c-431e-bd73-805fc0003fd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:18.856584Z",
     "iopub.status.busy": "2024-06-21T18:28:18.855959Z",
     "iopub.status.idle": "2024-06-21T18:28:18.859907Z",
     "shell.execute_reply": "2024-06-21T18:28:18.859298Z",
     "shell.execute_reply.started": "2024-06-21T18:28:18.856557Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_to_llm = (\n",
    "    f\"Read the objective statement and write the changes in the {selected_file_path} file based on the instructions and details provided.\\n\"\n",
    "    + str(code_spec)\n",
    "    + \"Here is the hierarchy \\n: \"\n",
    "    + display_file_hierarchy(file_hierarchy)\n",
    "    + \"Here is the source codes for all the files mentioned above in the hierarchy. \\n\"\n",
    "    + str(combined_context)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db5aad58-a057-4e07-860b-9d15068eade1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:19.823143Z",
     "iopub.status.busy": "2024-06-21T18:28:19.822851Z",
     "iopub.status.idle": "2024-06-21T18:28:36.952261Z",
     "shell.execute_reply": "2024-06-21T18:28:36.951669Z",
     "shell.execute_reply.started": "2024-06-21T18:28:19.823125Z"
    }
   },
   "outputs": [],
   "source": [
    "llm_output = runLlm(llm, prompt_to_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "008fe65c-6b65-4443-ae62-02670b632cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:36.953430Z",
     "iopub.status.busy": "2024-06-21T18:28:36.953243Z",
     "iopub.status.idle": "2024-06-21T18:28:36.956592Z",
     "shell.execute_reply": "2024-06-21T18:28:36.956088Z",
     "shell.execute_reply.started": "2024-06-21T18:28:36.953413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the objective statement and feature requirements, you will need to make changes to the `Multimodal-RAG\\chatapp\\chatapp\\chatapp.py` file to enhance the user experience by adding new chat functionalities, including maintaining chat history, enabling users to ask questions based on previous interactions, and managing chat resets and deletes.\n",
      "\n",
      "Here's how you can modify the `chatapp.py` to achieve the stated requirements:\n",
      "\n",
      "### Changes in `Multimodal-RAG\\chatapp\\chatapp\\chatapp.py`:\n",
      "\n",
      "1. **Import necessary components for chat reset and delete functionalities:**\n",
      "2. **Include chat functionalities in the navigation bar:**\n",
      "3. **Include state management for chat operations:**\n",
      "\n",
      "### Modified `Multimodal-RAG\\chatapp\\chatapp\\chatapp.py`:\n",
      "\n",
      "```python\n",
      "\"\"\"The main Chat app.\"\"\"\n",
      "\n",
      "import reflex as rx\n",
      "from chatapp.components import chat, navbar\n",
      "\n",
      "# Import State for managing current and new states\n",
      "from chatapp.state import State \n",
      "from chatapp import style\n",
      "\n",
      "def index() -> rx.Component:\n",
      "    \"\"\"The main app.\"\"\"\n",
      "    \n",
      "    return rx.chakra.vstack(\n",
      "        navbar(),\n",
      "        chat.chat(),\n",
      "        chat.action_bar(),\n",
      "        background_color=rx.color(\"mauve\", 1),\n",
      "        color=rx.color(\"mauve\", 12),\n",
      "        min_height=\"100vh\",\n",
      "        align_items=\"stretch\",\n",
      "        spacing=\"0\",\n",
      "    )\n",
      "\n",
      "def chat_management() -> rx.Component:\n",
      "    \"\"\"Component for managing chat functionalities.\"\"\"\n",
      "    \n",
      "    return rx.chakra.hstack(\n",
      "        rx.chakra.button(\n",
      "            \"Reset Chat\",\n",
      "            on_click=State.reset_chat\n",
      "        ),\n",
      "        rx.chakra.button(\n",
      "            \"Delete Chat\",\n",
      "            on_click=State.delete_chat\n",
      "        )\n",
      "    )\n",
      "\n",
      "# Add state and page to the app.\n",
      "app = rx.App(\n",
      "    theme=rx.theme(\n",
      "        appearance=\"dark\",\n",
      "        accent_color=\"violet\",\n",
      "    ),\n",
      ")\n",
      "\n",
      "app.add_page(index)\n",
      "app.add_page(chat_management, route=\"manage_chat\")\n",
      "```\n",
      "\n",
      "Here we have made three changes:\n",
      "\n",
      "1. Imported the `State` class from `chatapp.state`.\n",
      "2. Created a `chat_management` page/component to handle the chat reset and delete functionalities.\n",
      "3. Added a `chat_management` page and its corresponding route to the app.\n",
      "\n",
      "### Changes in `Multimodal-RAG\\chatapp\\chatapp\\state.py` to support the new functionalities:\n",
      "\n",
      "Since `state.py` already contains methods for creating and deleting chats, we will just add a method for resetting the current chat:\n",
      "\n",
      "### Modified `Multimodal-RAG\\chatapp\\chatapp\\state.py`:\n",
      "\n",
      "```python\n",
      "import os\n",
      "import reflex as rx\n",
      "from openai import OpenAI\n",
      "import asyncio\n",
      "import requests\n",
      "import json\n",
      "from typing import List, Tuple\n",
      "\n",
      "\n",
      "# Checking if the API key is set properly\n",
      "if not os.getenv(\"openaikey\"):\n",
      "    raise Exception(\"Please set openaikey environment variable.\")\n",
      "\n",
      "\n",
      "class QA(rx.Base):\n",
      "    \"\"\"A question and answer pair.\"\"\"\n",
      "\n",
      "    question: str\n",
      "    answer: str\n",
      "    sources: List[Tuple[int, str]]\n",
      "\n",
      "\n",
      "DEFAULT_CHATS = {\n",
      "    \"My Chat\": [],\n",
      "}\n",
      "\n",
      "\n",
      "class State(rx.State):\n",
      "    \"\"\"The app state.\"\"\"\n",
      "\n",
      "    # A dict from the chat name to the list of questions and answers.\n",
      "    chats: dict[str, list[QA]] = DEFAULT_CHATS\n",
      "    \n",
      "    # The current chat name.\n",
      "    current_chat = \"My Chat\"\n",
      "\n",
      "    # The current question.\n",
      "    question: str\n",
      "\n",
      "    # Whether we are processing the question.\n",
      "    processing: bool = False\n",
      "\n",
      "    # The name of the new chat.\n",
      "    new_chat_name: str = \"\"\n",
      "    \n",
      "    backend_url: str = \"http://localhost:8001/answer\"\n",
      "    \n",
      "    def create_chat(self):\n",
      "        \"\"\"Create a new chat.\"\"\"\n",
      "        # Add the new chat to the list of chats.\n",
      "        self.current_chat = self.new_chat_name\n",
      "        self.chats[self.new_chat_name] = []\n",
      "\n",
      "    def delete_chat(self):\n",
      "        \"\"\"Delete the current chat.\"\"\"\n",
      "        del self.chats[self.current_chat]\n",
      "        if len(self.chats) == 0:\n",
      "            self.chats = DEFAULT_CHATS\n",
      "        self.current_chat = list(self.chats.keys())[0]\n",
      "        \n",
      "    def reset_chat(self):\n",
      "        \"\"\"Reset the current chat.\"\"\"\n",
      "        self.chats[self.current_chat] = []\n",
      "\n",
      "    def set_chat(self, chat_name: str):\n",
      "        \"\"\"Set the name of the current chat.\n",
      "\n",
      "        Args:\n",
      "            chat_name: The name of the chat.\n",
      "        \"\"\"\n",
      "        self.current_chat = chat_name\n",
      "\n",
      "    @rx.var\n",
      "    def chat_titles(self) -> list[str]:\n",
      "        \"\"\"Get the list of chat titles.\n",
      "\n",
      "        Returns:\n",
      "            The list of chat names.\n",
      "        \"\"\"\n",
      "        return list(self.chats.keys())\n",
      "\n",
      "    async def process_question(self, form_data: dict[str, str\n"
     ]
    }
   ],
   "source": [
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5a73705-ab4e-4966-8d65-82ada392528e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:45.905063Z",
     "iopub.status.busy": "2024-06-21T18:28:45.904786Z",
     "iopub.status.idle": "2024-06-21T18:28:45.908418Z",
     "shell.execute_reply": "2024-06-21T18:28:45.907758Z",
     "shell.execute_reply.started": "2024-06-21T18:28:45.905044Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_python_code(text):\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'```python(.*?)```'\n",
    "    \n",
    "    # Use re.findall to extract all occurrences\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10a0d831-d488-462c-99e2-07218ed116c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:46.822822Z",
     "iopub.status.busy": "2024-06-21T18:28:46.822425Z",
     "iopub.status.idle": "2024-06-21T18:28:46.826270Z",
     "shell.execute_reply": "2024-06-21T18:28:46.825628Z",
     "shell.execute_reply.started": "2024-06-21T18:28:46.822794Z"
    }
   },
   "outputs": [],
   "source": [
    "code_update = extract_python_code(llm_output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bec298d3-6adb-444b-97a4-d9fa98806873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:48.082187Z",
     "iopub.status.busy": "2024-06-21T18:28:48.081870Z",
     "iopub.status.idle": "2024-06-21T18:28:48.085920Z",
     "shell.execute_reply": "2024-06-21T18:28:48.085220Z",
     "shell.execute_reply.started": "2024-06-21T18:28:48.082144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"\"\"The main Chat app.\"\"\"\n",
      "\n",
      "import reflex as rx\n",
      "from chatapp.components import chat, navbar\n",
      "\n",
      "# Import State for managing current and new states\n",
      "from chatapp.state import State \n",
      "from chatapp import style\n",
      "\n",
      "def index() -> rx.Component:\n",
      "    \"\"\"The main app.\"\"\"\n",
      "    \n",
      "    return rx.chakra.vstack(\n",
      "        navbar(),\n",
      "        chat.chat(),\n",
      "        chat.action_bar(),\n",
      "        background_color=rx.color(\"mauve\", 1),\n",
      "        color=rx.color(\"mauve\", 12),\n",
      "        min_height=\"100vh\",\n",
      "        align_items=\"stretch\",\n",
      "        spacing=\"0\",\n",
      "    )\n",
      "\n",
      "def chat_management() -> rx.Component:\n",
      "    \"\"\"Component for managing chat functionalities.\"\"\"\n",
      "    \n",
      "    return rx.chakra.hstack(\n",
      "        rx.chakra.button(\n",
      "            \"Reset Chat\",\n",
      "            on_click=State.reset_chat\n",
      "        ),\n",
      "        rx.chakra.button(\n",
      "            \"Delete Chat\",\n",
      "            on_click=State.delete_chat\n",
      "        )\n",
      "    )\n",
      "\n",
      "# Add state and page to the app.\n",
      "app = rx.App(\n",
      "    theme=rx.theme(\n",
      "        appearance=\"dark\",\n",
      "        accent_color=\"violet\",\n",
      "    ),\n",
      ")\n",
      "\n",
      "app.add_page(index)\n",
      "app.add_page(chat_management, route=\"manage_chat\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(code_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b1fa0-79d7-4dd0-8a00-e9707dde8a0e",
   "metadata": {},
   "source": [
    "## Part G: Perform a PR to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91dc5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication to Github\n",
    "GITHUB_TOKEN = input(\"Please enter your GitHub token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4d877ac-6b96-449e-b05d-f7e85de5c69e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:58.192826Z",
     "iopub.status.busy": "2024-06-21T18:28:58.192551Z",
     "iopub.status.idle": "2024-06-21T18:28:58.196717Z",
     "shell.execute_reply": "2024-06-21T18:28:58.195932Z",
     "shell.execute_reply.started": "2024-06-21T18:28:58.192808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill out the reqs to make a PR\n",
    "REPO_NAME = 'Multimodal-RAG'\n",
    "NEW_BRANCH_NAME = 'speech2code'\n",
    "BASE_BRANCH = 'develop'\n",
    "FILE_PATH = selected_file_path\n",
    "COMMIT_MESSAGE = 'Test Commit'\n",
    "PR_TITLE = 'Test Hackthon'\n",
    "PR_BODY = 'Adding a comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef8a5950-9a30-46a6-b9c7-f45b2ce3f52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:58.990751Z",
     "iopub.status.busy": "2024-06-21T18:28:58.990474Z",
     "iopub.status.idle": "2024-06-21T18:28:58.994051Z",
     "shell.execute_reply": "2024-06-21T18:28:58.993263Z",
     "shell.execute_reply.started": "2024-06-21T18:28:58.990733Z"
    }
   },
   "outputs": [],
   "source": [
    "new_content_str = code_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda7bbc-e7ad-4ec1-8b08-73fa0ba59ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:28:59.823981Z",
     "iopub.status.busy": "2024-06-21T18:28:59.823630Z",
     "iopub.status.idle": "2024-06-21T18:29:03.969177Z",
     "shell.execute_reply": "2024-06-21T18:29:03.968341Z",
     "shell.execute_reply.started": "2024-06-21T18:28:59.823956Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    g = Github(GITHUB_TOKEN)\n",
    "    # Get the repository\n",
    "    repo = g.get_repo(REPO_NAME)\n",
    "    base_branch_ref = repo.get_git_ref(f\"heads/{BASE_BRANCH}\")\n",
    "    repo.create_git_ref(ref=f\"refs/heads/{NEW_BRANCH_NAME}\", sha=base_branch_ref.object.sha)\n",
    "    print(f\"Branch '{NEW_BRANCH_NAME}' created successfully.\")\n",
    "\n",
    "    # Get the file content\n",
    "    file_content = repo.get_contents(FILE_PATH, ref=NEW_BRANCH_NAME)\n",
    "    # Decode the content to a string\n",
    "    content_str = file_content.decoded_content.decode('utf-8')\n",
    "\n",
    "    # Modify the file content (example modification: append a line)\n",
    "    new_content_str = content_str + code_update\n",
    "\n",
    "    # Update the file with new content\n",
    "    repo.update_file(\n",
    "        path=FILE_PATH,\n",
    "        message=\"Modify existing file in new branch\",\n",
    "        content=new_content_str,\n",
    "        sha=file_content.sha,\n",
    "        branch=NEW_BRANCH_NAME\n",
    "    )\n",
    "    print(f\"File '{FILE_PATH}' modified successfully in branch '{NEW_BRANCH_NAME}'.\")\n",
    "\n",
    "    # Create the pull request\n",
    "    pr = repo.create_pull(\n",
    "        title=f\"Modify existing file {Path(selected_file_path).stem} in new branch\",\n",
    "        body=\"This pull request modifies an existing file in the new branch.\",\n",
    "        head=NEW_BRANCH_NAME,\n",
    "        base=BASE_BRANCH\n",
    "    )\n",
    "\n",
    "    print(f\"Pull Request created: {pr.html_url}\")\n",
    "\n",
    "except GithubException as e:\n",
    "    print(f\"Failed to create branch or pull request: {e.data}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "has_local_update": false,
  "is_local": true,
  "is_remote": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "last_sync_time": "2024-06-21T17:30:00.867861"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
